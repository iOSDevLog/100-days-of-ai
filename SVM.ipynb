{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1  Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = [3,4]\n",
    "np.linalg.norm(x) # 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute the direction of a vector x.\n",
    "def direction(x):\n",
    "    return x/np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6 0.8]\n"
     ]
    }
   ],
   "source": [
    "u = np.array([3,4])\n",
    "w = direction(u)\n",
    "print (w) # [0.6 , 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6 0.8]\n",
      "[0.6 0.8]\n"
     ]
    }
   ],
   "source": [
    "u_1 = np.array([3,4])\n",
    "u_2 = np.array([30,40])\n",
    "\n",
    "print (direction(u_1)) # [0.6 , 0.8]\n",
    "print (direction(u_2)) # [0.6 , 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.array([0.6, 0.8])) # 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def geometric_dot_product(x,y, theta):\n",
    "    x_norm = np.linalg.norm(x)\n",
    "    y_norm = np.linalg.norm(y)\n",
    "    return x_norm * y_norm * math.cos(math.radians(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.00000000000001\n"
     ]
    }
   ],
   "source": [
    "theta = 45\n",
    "\n",
    "x = [3,5]\n",
    "y = [8,2]\n",
    "\n",
    "print (geometric_dot_product(x,y,theta))  # 34.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x,y):\n",
    "    result = 0\n",
    "    for i in range(len(x)):\n",
    "        result = result + x[i]*y[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "x = [3,5]\n",
    "y = [8,2]\n",
    "print (dot_product(x,y)) # 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([3,5])\n",
    "y = np.array([8,2])\n",
    "\n",
    "print (np.dot(x,y)) # 34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2  The Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def perceptron_learning_algorithm(X, y):\n",
    "    w = np.random.rand(3)   # can also be initialized at zero.\n",
    "    misclassified_examples = predict(hypothesis, X, y, w)\n",
    "\n",
    "    while misclassified_examples.any():\n",
    "        x, expected_y = pick_one_from(misclassified_examples, X, y)\n",
    "        w = w + x * expected_y  # update rule\n",
    "        misclassified_examples = predict(hypothesis, X, y, w)\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(x, w):\n",
    "    return np.sign(np.dot(w, x))\n",
    "\n",
    "\n",
    "# Make predictions on all data points\n",
    "# and return the ones that are misclassified.\n",
    "def predict(hypothesis_function, X, y, w):\n",
    "    predictions = np.apply_along_axis(hypothesis_function, 1, X, w)\n",
    "    misclassified = X[y != predictions]\n",
    "    return misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one misclassified example randomly\n",
    "# and return it with its expected label.\n",
    "def pick_one_from(misclassified_examples, X, y):\n",
    "    np.random.shuffle(misclassified_examples)\n",
    "    x = misclassified_examples[0]\n",
    "    index = np.where(np.all(X == x, axis=1))\n",
    "    return x, y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-44.35244895   1.50714969   5.52834138]\n"
     ]
    }
   ],
   "source": [
    "# See Appendix A for more information about the dataset \n",
    "from succinctly.datasets import get_dataset, linearly_separable as ls\n",
    "np.random.seed(88)\n",
    "X, y = get_dataset(ls.get_training_examples)\n",
    "\n",
    "# transform X into an array of augmented vectors.\n",
    "X_augmented = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "w = perceptron_learning_algorithm(X_augmented, y)\n",
    "\n",
    "print (w) # [-44.35244895   1.50714969   5.52834138]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rule(expected_y, w, x):\n",
    "    if expected_y == 1:\n",
    "        w = w + x\n",
    "    else:\n",
    "        w = w - x\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rule(expected_y, w, x):\n",
    "    w = w + x * expected_y\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def hypothesis(x, w):\n",
    "    return np.sign(np.dot(w, x))\n",
    "\n",
    "x = np.array([1, 2, 7])\n",
    "expected_y = -1\n",
    "w = np.array([4, 5, 3])\n",
    "\n",
    "print(hypothesis(w, x))             # The predicted y is 1.\n",
    "\n",
    "w = update_rule(expected_y, w, x)   # we apply the update rule.\n",
    " \n",
    "print (hypothesis(w, x))             # The predicted y is -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "x = np.array([1, 3])\n",
    "expected_y = -1\n",
    "w = np.array([5, 3])\n",
    "\n",
    "print (hypothesis(w, x))            # The predicted y is 1.\n",
    "\n",
    "w = update_rule(expected_y, w, x)  # we apply the update rule.\n",
    "\n",
    "print(hypothesis(w, x))             # The predicted y is 1.\n",
    "\n",
    "w = update_rule(expected_y, w, x)   # we apply the update rule.\n",
    " \n",
    "print (hypothesis(w, x))             # The predicted y is -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3  The SVM Optimization Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the functional margin of an example (x,y)\n",
    "# with respect to a hyperplane defined by w and b.\n",
    "def example_functional_margin(w, b, x, y):\n",
    "    result = y * (np.dot(w, x) + b)\n",
    "    return result\n",
    "\n",
    "# Compute the functional margin of a hyperplane\n",
    "# for examples X with labels y.\n",
    "def functional_margin(w, b, X, y):\n",
    "    return np.min([example_functional_margin(w, b, x, y[i])\n",
    "                  for i, x in enumerate(X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 1])\n",
    "y = 1\n",
    "\n",
    "b_1 = 5\n",
    "w_1 = np.array([2, 1])\n",
    "\n",
    "w_2 = w_1 * 10\n",
    "b_2 = b_1 * 10\n",
    "\n",
    "print (example_functional_margin(w_1, b_1, x, y))  # 8\n",
    "print (example_functional_margin(w_2, b_2, x, y))  # 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the geometric margin of an example (x,y)\n",
    "# with respect to a hyperplane defined by w and b.\n",
    "def example_geometric_margin(w, b, x, y):\n",
    "    norm = np.linalg.norm(w)\n",
    "    result = y * (np.dot(w/norm, x) + b/norm)\n",
    "    return result\n",
    "\n",
    "# Compute the geometric margin of a hyperplane\n",
    "# for examples X with labels y.\n",
    "def geometric_margin(w, b, X, y):\n",
    "    return np.min([example_geometric_margin(w, b, x, y[i])\n",
    "                  for i, x in enumerate(X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.577708763999664\n",
      "3.577708763999664\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,1])\n",
    "y = 1\n",
    "\n",
    "b_1 = 5\n",
    "w_1 = np.array([2,1])\n",
    "\n",
    "w_2 = w_1*10\n",
    "b_2 = b_1*10\n",
    "\n",
    "print (example_geometric_margin(w_1, b_1, x, y))  # 3.577708764\n",
    "print (example_geometric_margin(w_2, b_2, x, y))  # 3.577708764"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18569533817705164\n",
      "0.6499336836196807\n"
     ]
    }
   ],
   "source": [
    "# Compare two hyperplanes using the geometrical margin.\n",
    "\n",
    "positive_x = [[2,7],[8,3],[7,5],[4,4],[4,6],[1,3],[2,5]]\n",
    "negative_x = [[8,7],[4,10],[9,7],[7,10],[9,6],[4,8],[10,10]]\n",
    "\n",
    "X = np.vstack((positive_x, negative_x))\n",
    "y = np.hstack((np.ones(len(positive_x)), -1*np.ones(len(negative_x))))\n",
    "\n",
    "w = np.array([-0.4, -1])\n",
    "b = 8\n",
    "\n",
    "# change the value of b\n",
    "print (geometric_margin(w, b, X, y))          # 0.185695338177\n",
    "print (geometric_margin(w, 8.5, X, y))        # 0.64993368362"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4  Solving the Optimization Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.9356e+00 -7.2072e+00  4e+01  6e+00  2e+00\n",
      " 1: -5.9831e+00 -4.3032e+00  1e+01  2e+00  6e-01\n",
      " 2: -5.6350e-01 -1.1535e+00  2e+00  1e-01  4e-02\n",
      " 3: -6.2758e-01 -7.4538e-01  1e-01  2e-16  9e-15\n",
      " 4: -7.1507e-01 -7.1641e-01  1e-03  1e-16  1e-14\n",
      " 5: -7.1604e-01 -7.1605e-01  1e-05  2e-16  1e-14\n",
      " 6: -7.1605e-01 -7.1605e-01  1e-07  1e-16  1e-14\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "# See Appendix A for more information about the dataset \n",
    "from succinctly.datasets import get_dataset, linearly_separable as ls\n",
    "import cvxopt.solvers\n",
    "X, y = get_dataset(ls.get_training_examples)\n",
    "m = X.shape[0]\n",
    "# Gram matrix - The matrix of all possible inner products of X.\n",
    "K = np.array([np.dot(X[i], X[j])\n",
    "              for j in range(m)\n",
    "              for i in range(m)]).reshape((m, m))\n",
    "\n",
    "P = cvxopt.matrix(np.outer(y, y) * K)\n",
    "q = cvxopt.matrix(-1 * np.ones(m))\n",
    "\n",
    "# Equality constraints\n",
    "A = cvxopt.matrix(y, (1, m))\n",
    "b = cvxopt.matrix(0.0)\n",
    "\n",
    "# Inequality constraints\n",
    "G = cvxopt.matrix(np.diag(-1 * np.ones(m)))\n",
    "h = cvxopt.matrix(np.zeros(m))\n",
    "\n",
    "# Solve the problem\n",
    "solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "# Lagrange multipliers\n",
    "multipliers = np.ravel(solution['x'])\n",
    "\n",
    "# Support vectors have positive multipliers.\n",
    "has_positive_multiplier = multipliers > 1e-7\n",
    "sv_multipliers = multipliers[has_positive_multiplier]\n",
    "\n",
    "support_vectors = X[has_positive_multiplier]\n",
    "support_vectors_y = y[has_positive_multiplier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_w(multipliers, X, y):\n",
    "    return np.sum(multipliers[i] * y[i] * X[i]\n",
    "                  for i in range(len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44444446 1.11111114]\n",
      "[0.44444453 1.11111128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "w = compute_w(multipliers, X, y)\n",
    "w_from_sv = compute_w(sv_multipliers, support_vectors, support_vectors_y)\n",
    "print (w)          # [0.44444446 1.11111114]\n",
    "print (w_from_sv)  # [0.44444453 1.11111128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_b(w, X, y):\n",
    "    return np.sum([y[i] - np.dot(w, X[i]) \n",
    "                   for i in range(len(X))])/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = compute_b(w, support_vectors, support_vectors_y) # -9.666668268506335"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5  Soft Margin SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = np.array([0.4, 1])\n",
    "b = -10\n",
    "\n",
    "x = np.array([6, 8])\n",
    "y = -1\n",
    "\n",
    "\n",
    "def constraint(w, b, x, y):\n",
    "    return y * (np.dot(w, x) + b) \n",
    "def hard_constraint_is_satisfied(w, b, x, y):\n",
    "    return constraint(w, b, x, y) >= 1\n",
    "\n",
    "\n",
    "def soft_constraint_is_satisfied(w, b, x, y, zeta):\n",
    "    return constraint(w, b, x, y) >= 1 - zeta\n",
    "\n",
    "\n",
    "# While the constraint is not satisfied for the example (6,8).\n",
    "print (hard_constraint_is_satisfied(w, b, x, y))               # False\n",
    "\n",
    "# We can use zeta = 2 and satisfy the soft constraint.\n",
    "print (soft_constraint_is_satisfied(w, b, x, y, zeta=2))       # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# We can pick a huge zeta for every point\n",
    "# to always satisfy the soft constraint.\n",
    "print (soft_constraint_is_satisfied(w, b, x, y, zeta=10))   # True\n",
    "print (soft_constraint_is_satisfied(w, b, x, y, zeta=1000)) # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6  Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform a two-dimensional vector x into a three-dimensional vector.\n",
    "def transform(x):\n",
    "    return [x[0]**2, np.sqrt(2)*x[0]*x[1], x[1]**2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100.0\n"
     ]
    }
   ],
   "source": [
    "x1 = [3,6]\n",
    "x2 = [10,10]\n",
    "\n",
    "x1_3d = transform(x1)\n",
    "x2_3d = transform(x2)\n",
    "\n",
    "print (np.dot(x1_3d,x2_3d))  # 8100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_kernel(a, b):\n",
    "    return a[0]**2 * b[0]**2 + 2*a[0]*b[0]*a[1]*b[1] + a[1]**2 * b[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100\n"
     ]
    }
   ],
   "source": [
    "x1 = [3,6]\n",
    "x2 = [10,10]   # We do not transform the data.\n",
    "\n",
    "print (polynomial_kernel(x1, x2)) # 8100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_kernel(a, b, degree, constant=0):\n",
    "    result = sum([a[i] * b[i] for i in range(len(a))]) + constant\n",
    "    return pow(result, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100\n"
     ]
    }
   ],
   "source": [
    "x1 = [3,6]\n",
    "x2 = [10,10]\n",
    "# We do not transform the data.\n",
    "\n",
    "print (polynomial_kernel(x1, x2, degree=2)) # 8100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7  The SMO Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(x1, x2):\n",
    "    return np.dot(x1, x2.T)\n",
    "\n",
    "def objective_function_to_minimize(X, y, a, kernel):\n",
    "    m, n = np.shape(X)\n",
    "    return 1 / 2 * np.sum([a[i] * a[j] * y[i] * y[j]* kernel(X[i, :], X[j, :])\n",
    "                           for j in range(m)\n",
    "                           for i in range(m)])\\\n",
    "           - np.sum([a[i] for i in range(m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_bound_indexes(self):\n",
    "    return np.where(np.logical_and(self.alphas > 0,\n",
    "                                   self.alphas < self.C))[0]\n",
    "\n",
    "# First heuristic: loop  over examples where alpha is not 0 and not C\n",
    "# they are the most likely to violate the KKT conditions\n",
    "# (the non-bound subset).\n",
    "def first_heuristic(self):\n",
    "    num_changed = 0\n",
    "    non_bound_idx = self.get_non_bound_indexes()\n",
    "\n",
    "    for i in non_bound_idx:\n",
    "        num_changed += self.examine_example(i)\n",
    "    return num_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_routine(self):\n",
    "    num_changed = 0\n",
    "    examine_all = True\n",
    "\n",
    "    while num_changed > 0 or examine_all:\n",
    "        num_changed = 0\n",
    "\n",
    "        if examine_all:\n",
    "            for i in range(self.m):\n",
    "                num_changed += self.examine_example(i)\n",
    "        else:\n",
    "            num_changed += self.first_heuristic()\n",
    "\n",
    "        if examine_all:\n",
    "            examine_all = False\n",
    "        elif num_changed == 0:\n",
    "            examine_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_heuristic(self, non_bound_indices):\n",
    "    i1 = -1\n",
    "    if len(non_bound_indices) > 1:\n",
    "        max = 0\n",
    "\n",
    "    for j in non_bound_indices:\n",
    "        E1 = self.errors[j] - self.y[j]\n",
    "        step = abs(E1 - self.E2) # approximation\n",
    "        if step > max: \n",
    "            max = step\n",
    "            i1 = j\n",
    "    return i1\n",
    "\n",
    "def examine_example(self, i2):\n",
    "    self.y2 = self.y[i2]\n",
    "    self.a2 = self.alphas[i2]\n",
    "    self.X2 = self.X[i2]\n",
    "    self.E2 = self.get_error(i2)\n",
    "\n",
    "    r2 = self.E2 * self.y2\n",
    "\n",
    "    if not((r2 < -self.tol and self.a2 < self.C) or \n",
    "           (r2 > self.tol and self.a2 > 0)):\n",
    "        # The KKT conditions are met, SMO looks at another example.\n",
    "        return 0\n",
    "\n",
    "    # Second heuristic A: choose the Lagrange multiplier that\n",
    "    # maximizes the absolute error.\n",
    "    non_bound_idx = list(self.get_non_bound_indexes())\n",
    "    i1 = self.second_heuristic(non_bound_idx)\n",
    "\n",
    "    if i1 >= 0 and self.take_step(i1, i2):\n",
    "        return 1\n",
    "\n",
    "    # Second heuristic B: Look for examples making positive \n",
    "    # progress by looping over all non-zero and non-C alpha, \n",
    "    # starting at a random point.\n",
    "    if len(non_bound_idx) > 0:\n",
    "        rand_i = randrange(len(non_bound_idx))\n",
    "        for i1 in non_bound_idx[rand_i:] + non_bound_idx[:rand_i]:\n",
    "            if self.take_step(i1, i2):\n",
    "                return 1\n",
    "\n",
    "    # Second heuristic C: Look for examples making positive progress\n",
    "    # by looping over all possible examples, starting at a random \n",
    "    # point.\n",
    "    rand_i = randrange(self.m)\n",
    "    all_indices = list(range(self.m))\n",
    "    for i1 in all_indices[rand_i:] + all_indices[:rand_i]:\n",
    "        if self.take_step(i1, i2):\n",
    "            return 1\n",
    "\n",
    "    # Extremely degenerate circumstances, SMO skips the first example.\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8  Multi-Class SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_X():\n",
    "    return np.array([[1, 6], [1, 7], [2, 5], [2, 8],\n",
    "                     [4, 2], [4, 3], [5, 1], [5, 2],\n",
    "                     [5, 3], [6, 1], [6, 2], [9, 4],\n",
    "                     [9, 7], [10, 5], [10, 6], [11, 6],\n",
    "                     [5, 9], [5, 10], [5, 11], [6, 9],\n",
    "                     [6, 10], [7, 10], [8, 11]])\n",
    "\n",
    "\n",
    "def load_y():\n",
    "    return np.array([1, 1, 1, 1,\n",
    "                     2, 2, 2, 2, 2, 2, 2,\n",
    "                     3, 3, 3, 3, 3,\n",
    "                     4, 4, 4, 4, 4, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm  \n",
    "\n",
    "# Create a simple dataset\n",
    "X = load_X()\n",
    "y = load_y()\n",
    "# Transform the 4 classes problem\n",
    "# in 4 binary classes problems.\n",
    "y_1 = np.where(y == 1, 1, -1)\n",
    "y_2 = np.where(y == 2, 1, -1)\n",
    "y_3 = np.where(y == 3, 1, -1)\n",
    "y_4 = np.where(y == 4, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train one binary classifier on each problem.\n",
    "y_list = [y_1, y_2, y_3, y_4]\n",
    "classifiers = []\n",
    "for y_i in y_list:\n",
    "    clf = svm.SVC(kernel='linear', C=1000)\n",
    "    clf.fit(X, y_i)\n",
    "    classifiers.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(X, classifiers):\n",
    "    predictions = np.zeros((X.shape[0], len(classifiers)))\n",
    "    for idx, clf in enumerate(classifiers):\n",
    "        predictions[:, idx] = clf.predict(X)\n",
    "\n",
    "    # returns the class number if only one classifier predicted it\n",
    "    # returns zero otherwise.\n",
    "    return np.where((predictions == 1).sum(1) == 1,\n",
    "                    (predictions == 1).argmax(axis=1) + 1,\n",
    "                    0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(X, classifiers):\n",
    "    predictions = np.zeros((X.shape[0], len(classifiers)))\n",
    "    for idx, clf in enumerate(classifiers):\n",
    "        predictions[:, idx] = clf.decision_function(X) \n",
    "    # return the argmax of the decision function as suggested by Vapnik.\n",
    "    return np.argmax(predictions, axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "\n",
    "X = load_X()\n",
    "y = load_y()\n",
    "\n",
    "clf = LinearSVC(C=1000, random_state=88, multi_class='ovr')\n",
    "clf.fit(X,y)\n",
    "\n",
    "# Make predictions on two examples.\n",
    "X_to_predict = np.array([[5,5],[2,5]])\n",
    "print (clf.predict(X_to_predict)) # prints [2 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import mode\n",
    "from sklearn import svm\n",
    "import numpy as np \n",
    "\n",
    "# Predict the class having the max number of votes.\n",
    "def predict_class(X, classifiers, class_pairs):\n",
    "    predictions = np.zeros((X.shape[0], len(classifiers)))\n",
    "    for idx, clf in enumerate(classifiers):\n",
    "        class_pair = class_pairs[idx]\n",
    "        prediction = clf.predict(X)\n",
    "        predictions[:, idx] = np.where(prediction == 1,\n",
    "                                       class_pair[0], class_pair[1])\n",
    "    return mode(predictions, axis=1)[0].ravel().astype(int)\n",
    "\n",
    "X = load_X()\n",
    "y = load_y()\n",
    "\n",
    "# Create datasets.\n",
    "training_data = []\n",
    "class_pairs = list(combinations(set(y), 2))\n",
    "for class_pair in class_pairs:\n",
    "    class_mask = np.where((y == class_pair[0]) | (y == class_pair[1]))\n",
    "    y_i = np.where(y[class_mask] == class_pair[0], 1, -1)\n",
    "    training_data.append((X[class_mask], y_i))\n",
    "\n",
    "# Train one classifier per class.\n",
    "classifiers = []\n",
    "for data in training_data:\n",
    "    clf = svm.SVC(kernel='linear', C=1000)\n",
    "    clf.fit(data[0], data[1])\n",
    "    classifiers.append(clf)\n",
    "\n",
    "# Make predictions on two examples.\n",
    "X_to_predict = np.array([[5,5],[2,5]])\n",
    "print (predict_class(X_to_predict, classifiers, class_pairs)) # prints [2 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "X = load_X()\n",
    "y = load_y()\n",
    "\n",
    "# Train a multi-class classifier.\n",
    "clf = svm.SVC(kernel='linear', C=1000)\n",
    "clf.fit(X,y)\n",
    "\n",
    "# Make predictions on two examples.\n",
    "X_to_predict = np.array([[5,5],[2,5]])\n",
    "print (clf.predict(X_to_predict)) # prints [2 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(X, classifiers, distinct_classes, class_pairs):\n",
    "    results = []\n",
    "    for x_row in X:\n",
    "        \n",
    "        class_list = list(distinct_classes)\n",
    "        \n",
    "        # After each prediction, delete the rejected class \n",
    "        # until there is only one class.\n",
    "        while len(class_list) > 1:\n",
    "            # We start with the pair of the first and \n",
    "            # last element in the list.\n",
    "            class_pair = (class_list[0], class_list[-1])\n",
    "            classifier_index = class_pairs.index(class_pair) \n",
    "            y_pred = classifiers[classifier_index].predict(x_row)\n",
    "            \n",
    "            if y_pred == 1:\n",
    "                class_to_delete = class_pair[1]\n",
    "            else:\n",
    "                class_to_delete = class_pair[0]\n",
    "\n",
    "            class_list.remove(class_to_delete)\n",
    "            \n",
    "        results.append(class_list[0])\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "X = load_X()\n",
    "y = load_y()\n",
    "\n",
    "clf = svm.LinearSVC(C=1000, multi_class='crammer_singer')\n",
    "clf.fit(X,y)\n",
    "\n",
    "# Make predictions on two examples.\n",
    "X_to_predict = np.array([[5,5],[2,5]])\n",
    "print (clf.predict(X_to_predict)) # prints [4 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
